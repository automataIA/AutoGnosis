---
title: sentiment analysis using transformers
date: 2020-01-12
tags: ["markdown"]
image : "post/img/SA.jpg"
Description  : "Analisi del sentimento di un corpo di messaggi di testo tramite transformers..."
---

## Costruire un classificatore di sentiment

#### Introduzione ai Transformers

L‚Äôanalisi del sentiment √® un tipo di problema dell‚Äôelaborazione del linguaggio naturale che consiste nel determinare se un testo ha un sentiment positivo o negativo. Questo compito non √® cos√¨ facile come si potrebbe pensare, perch√© il linguaggio √® per definizione molto intricato e complesso. Ci√≤ √® ancora pi√π accentuato in questo tipo di insiemi di dati in cui si vuole valutare il sentiment sulla base di una recensione a testo libero, in quanto l‚Äôutente pu√≤ scriverci qualsiasi cosa decida. Storicamente, questo problema veniva risolto facendo una sorta di conteggio istruito delle parole positive rispetto a quelle negative per quantificare il sentiment complessivo del testo.

Come si pu√≤ immaginare, questo pu√≤ diventare complesso molto velocemente. Pensiamo a un esempio come la seguente recensione: ‚ÄúIl film era molto bello‚Äù. Speriamo che il nostro modello sia in grado di classificarla come positiva, poich√© si tratta di una recensione positiva. Ma ora pensiamo a un altro esempio come: ‚ÄúIl film non era molto bello‚Äù. Questa volta, la parola ‚Äúnon‚Äù nega la ‚Äúpositivit√†‚Äù della parola ‚Äúmolto buono‚Äù, e quindi non √® facile per un modello capire questa complessit√† se si limita a contare il sentiment positivo o negativo.

Il tipo successivo di modelli che abbiamo provato √® stato quello delle Reti Neurali Ricorrenti. Questi modelli cercano di comprendere la relazione **sequenziale** tra le parole di una frase, costruendo fondamentalmente una rete che considera i risultati dei token o delle parole precedenti per prevedere quella successiva. In questo modo si ottengono reti pi√π potenti, poich√© il linguaggio √® per definizione sequenziale. Questo concetto di sequenzialit√† √® ci√≤ che generalmente chiamiamo **contesto**. Utilizzando queste reti (in particolare le RNN e le LSTM), i modelli linguistici sono diventati molto pi√π sofisticati, in quanto sono stati in grado di fare previsioni basate sulle parole precedenti apparse nella frase. Ma questo aveva un problema: il contesto √® di natura **bidirezionale**. Ci√≤ significa che potremmo riferirci a un token che viene **dopo** il token, non solo prima. E questi modelli tendono a fallire nei casi in cui il contesto √® pi√π legato alle parole che seguono la parola che stiamo passando al modello.

Cos√¨, qualche anno fa, √® arrivato un nuovo giocatore che ha rivoluzionato il mondo del Deep Learning, dapprima nel campo della PNL, ma ora si √® diversificato e li si pu√≤ vedere ovunque, e si chiamano **Transformers**. Utilizzando un meccanismo chiamato auto-attenzione e bidirezionalit√†, i primi trasformatori erano in grado di introdurre un **contesto** alle frasi in entrambe le direzioni, comprendendo contemporaneamente **quali token fossero rilevanti** per il significato della frase. Utilizzando enormi insiemi di dati, questi modelli basati sui trasformatori hanno conquistato il mondo dell‚ÄôNLP. Oggi utilizzeremo un tipo particolare di modello pre-addestrato per l‚Äôanalisi del sentimento per cercare di dedurre il sentimento di una determinata recensione cinematografica.

### Introduzione alla libreria di trasformatori HuggingFace

La libreria **transformers** di HugginFace ü§ó ci consente di accedere gratuitamente a questi modelli di transformer pre-addestrati! Questi modelli possono quindi essere messi a punto per eseguire un‚Äôattivit√† specifica che vogliamo svolgere con essi. Ancora meglio, HuggingFace offre gi√† una serie di modelli di trasformatore che sono stati messi a punto per eseguire diverse attivit√†. Se vuoi saperne di pi√π sui diversi modelli perfezionati offerti da huggingface, visita [questo link](https://huggingface.co/docs/transformers/main_classes/pipelines). Per questo esercizio utilizzeremo il modello di analisi del sentimento offerto nella classe **pipeline**.

Per prima cosa, dobbiamo installare la libreria transformers nel kernel (o nel tuo computer locale, se stai eseguendo questo processo localmente. Quindi importeremo semplicemente la classe ‚Äúpipeline‚Äù dalla libreria transformers, insieme ad alcune librerie extra che saranno utile per leggere i dati e calcolare l‚Äôaccuratezza del modello.

```
! pip install transformers
```

```
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from transformers import pipeline
```

### Leggi i dati

Per utilizzare il modello, leggeremo i dati dalla cartella movie.csv nel kernel, che contiene molte recensioni di film in una colonna ‚Äútext‚Äù e un tag che indica se il sentiment del testo per quella voce √® positivo (1) o negativo (0), indicato dal nome della colonna ‚Äúlabel‚Äù. La parte di inferenza del processo che utilizza i modelli pre-addestrati pu√≤ richiedere molto tempo, quindi limiteremo il processo a un campione che contiene 2000 recensioni positive e 2000 recensioni negative, poich√© vogliamo semplicemente testare il modello pre-addestrato e vedere quale accuratezza otteniamo.

Per visualizzare i risultati, salveremo la prima riga come esempio per testare il modello e verificare che l‚Äôoutput sia quello desiderato. Questo √® ci√≤ che faremo di seguito nella variabile ‚Äútest\_drive‚Äù.

```
df = pd.read_csv('/kaggle/input/imdb-movie-ratings-sentiment-analysis/movie.csv')

test_drive = df.iloc[0]
test_drive
```

### Testando il modello pipeline da HF

Ora facciamo un‚Äôinferenza su un testo con il modello, usando l‚Äôoggetto **pipeline** di HuggingFace. L‚Äôoggetto pipeline ci permette di creare un‚Äôistanza del modello pre-addestrato di cui abbiamo parlato prima e di effettuare rapide chiamate di inferenza per ottenere una predizione. Il modello che caricheremo √® un modello PyTorch, quindi dobbiamo usare la sua API per fare una previsione. L‚ÄôAPI √® semplicemente: model(‚Äúcosa si vuole predire‚Äù)

Un aspetto da tenere in considerazione √® che il modello carica di default il modello BERT uncased, un trasformatore bidirezionale sviluppato da Google. Il modello consente di inserire testi che possono essere lunghi fino a **512 tokens**, quindi dobbiamo fare attenzione. I testi in questo set di dati sono spesso pi√π lunghi, quindi dobbiamo essere pronti a risolvere questo problema.

Se siete interessati, il modello ha come default **Distil-BERT**, che √® una versione pi√π leggera del modello completo. Questo modello √® addestrato in inglese e non fa distinzione tra caratteri maiuscoli e minuscoli. √à un buon punto di partenza ed √® anche il modello predefinito. Se siete interessati, posso anche pubblicare un altro quaderno per provare diversi modelli pre-addestrati e verificare come si comportano gli uni rispetto agli altri per questo compito.

Il processo di inferenza del modello BERT richiede un po‚Äô di tempo, quindi lo eseguiremo su un sottoinsieme del nostro DataFrame originale, solo per ridurre i costi di calcolo. Se volete testare il modello sull‚Äôintero dataset di 40.000 voci, potete farlo, ma ci vorr√† un po‚Äô di tempo. Basta cambiare inference\_df per puntare all‚Äôintero dataset (df) eseguendo il seguente comando (si tenga presente che l‚Äôaccuratezza sar√† quasi identica):

```
smaller_df = pd.concat([
    df[df['label'] == 1].sample(2000, random_state=101),
    df[df['label'] == 0].sample(2000, random_state=101)
])

inference_df = smaller_df.copy()
```

### Costruire il modello per Sentiment Analysis

L‚Äôunica cosa di cui abbiamo bisogno ora per usare il modello √® istanziare la classe pipeline e salvarla in una variabile chiamata ‚Äúmodel‚Äù. **L‚Äôoutput dell‚Äôoggetto pipeline √® il modello pre-addestrato** con i suoi pesi, quindi √® sufficiente passare un testo attraverso il modello per ottenere una previsione.

Ricordiamo che **dobbiamo ancora ridurre il numero di token (parole)** al numero massimo consentito dal modello BERT pre-addestrato. Lo faremo semplicemente troncando i risultati a 512 token al massimo. In altre parole, se la stringa contiene pi√π di 512 parole, √® sufficiente mantenere le prime 512.

Dopodich√©, l‚Äôunica cosa che resta da fare √® calcolare l‚Äôaccuratezza del modello cos√¨ com‚Äô√®. Lo faremo utilizzando la funzione accuracy\_score della libreria sklearn.metrics. Procediamo di seguito:

```
model = pipeline('sentiment-analysis')
```

```
model(test_drive['text'])
```

Pre-elaboriamo il DataFrame in modo che non contenga frasi pi√π grandi di 512 parole (token).

```
inference_df['text'] = inference_df['text'].map(lambda x: x if len(x.split(' ')) <= 280 else ' '.join(x.split(' ')[:280]))
```

```
y_pred = model(inference_df['text'].to_list())
y_pred_values = [1 if dictionary['label'] == 'POSITIVE' else 0 for dictionary in y_pred]
y_pred_values
```

```
y_true = inference_df['label']

accuracy_score(y_true, y_pred_values)
```

```
print(classification_report(y_true, y_pred_values))
print(confusion_matrix(y_true, y_pred_values))
```

### Conclusioni

Alla fine, otteniamo un modello che prevede correttamente l'89% delle recensioni, senza alcun addestramento! I modelli di HuggingFace sono ottimi strumenti di base e possono funzionare molto bene anche se si decide di non metterli a punto. Se avete un compito di sentiment analysis e non avete il tempo o le conoscenze tecniche per ri-addestrare questo modello sui vostri dati, potete provare questo approccio e vedere voi stessi che i risultati possono essere davvero buoni!


###### _**Questo notebook preso da [Kaggle](https://www.kaggle.com/code/rererel/89-accuracy-with-4-lines-of-code-using-hf/edit) √® stato tradotto in italiano. Volendo sottolineare le potenzialit√† dei TRANSFORMER e dei modelli PRE-ADDESTRATI, che tramite poche righe di codice riesce a fare risultati notevoli.**_